{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6747022,"sourceType":"datasetVersion","datasetId":3884767}],"dockerImageVersionId":30529,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\n\nimport numpy as np\n\nimport jax\nimport jax.numpy as jnp\nfrom jax import grad, jit\n\nfrom jax.tree_util import tree_map\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score\n\nimport optax\n\nfrom flax import linen as nn\nfrom flax.training import train_state\nfrom flax.serialization import (\n    to_state_dict, msgpack_serialize, from_bytes\n)\n\nimport os\nimport wandb\nfrom typing import Callable\nfrom tqdm.notebook import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-28T09:40:02.649538Z","iopub.execute_input":"2023-11-28T09:40:02.649913Z","iopub.status.idle":"2023-11-28T09:40:03.336167Z","shell.execute_reply.started":"2023-11-28T09:40:02.649882Z","shell.execute_reply":"2023-11-28T09:40:03.335319Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"%%writefile train_zl.sh\nexport MODEL_NAME=\"stabilityai/stable-diffusion-xl-base-1.0\"","metadata":{"execution":{"iopub.status.busy":"2023-11-28T07:28:51.941346Z","iopub.execute_input":"2023-11-28T07:28:51.941671Z","iopub.status.idle":"2023-11-28T07:28:51.947613Z","shell.execute_reply.started":"2023-11-28T07:28:51.941635Z","shell.execute_reply":"2023-11-28T07:28:51.946426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!export TEST_NAME='tyup'\n!echo $TEST_NAME","metadata":{"execution":{"iopub.status.busy":"2023-11-28T07:28:51.948847Z","iopub.execute_input":"2023-11-28T07:28:51.949102Z","iopub.status.idle":"2023-11-28T07:28:53.916723Z","shell.execute_reply.started":"2023-11-28T07:28:51.949080Z","shell.execute_reply":"2023-11-28T07:28:53.915479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ecom_data = pd.read_csv('/kaggle/input/jax-datasets/ecommerce_data.csv')\necom_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-28T07:28:53.919956Z","iopub.execute_input":"2023-11-28T07:28:53.920320Z","iopub.status.idle":"2023-11-28T07:28:53.959470Z","shell.execute_reply.started":"2023-11-28T07:28:53.920285Z","shell.execute_reply":"2023-11-28T07:28:53.958563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ecom_data = ecom_data.drop(['Email','Avatar','Address'], axis = 1)\necom_data.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-28T07:28:53.960472Z","iopub.execute_input":"2023-11-28T07:28:53.960732Z","iopub.status.idle":"2023-11-28T07:28:53.970142Z","shell.execute_reply.started":"2023-11-28T07:28:53.960709Z","shell.execute_reply":"2023-11-28T07:28:53.969167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = ecom_data.drop('Yearly Amount Spent', axis = 1)\ny = ecom_data['Yearly Amount Spent']","metadata":{"execution":{"iopub.status.busy":"2023-11-28T07:28:53.971530Z","iopub.execute_input":"2023-11-28T07:28:53.971837Z","iopub.status.idle":"2023-11-28T07:28:53.977956Z","shell.execute_reply.started":"2023-11-28T07:28:53.971791Z","shell.execute_reply":"2023-11-28T07:28:53.976860Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-28T07:28:53.979208Z","iopub.execute_input":"2023-11-28T07:28:53.979518Z","iopub.status.idle":"2023-11-28T07:28:53.990196Z","shell.execute_reply.started":"2023-11-28T07:28:53.979493Z","shell.execute_reply":"2023-11-28T07:28:53.989341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler = StandardScaler()\n\nX_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\nX_test_scaled = pd.DataFrame(scaler.fit_transform(X_test), columns=X_test.columns)","metadata":{"execution":{"iopub.status.busy":"2023-11-28T07:28:53.991465Z","iopub.execute_input":"2023-11-28T07:28:53.992140Z","iopub.status.idle":"2023-11-28T07:28:54.004637Z","shell.execute_reply.started":"2023-11-28T07:28:53.992107Z","shell.execute_reply":"2023-11-28T07:28:54.003439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_scaled.describe()","metadata":{"execution":{"iopub.status.busy":"2023-11-28T07:28:54.006088Z","iopub.execute_input":"2023-11-28T07:28:54.006825Z","iopub.status.idle":"2023-11-28T07:28:54.034740Z","shell.execute_reply.started":"2023-11-28T07:28:54.006789Z","shell.execute_reply":"2023-11-28T07:28:54.033849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = jnp.array(X_train_scaled.to_numpy(), dtype = jnp.float32), jnp.array(X_test_scaled.to_numpy(), dtype = jnp.float32), jnp.array(y_train.to_numpy(), dtype = jnp.float32), jnp.array(y_test.to_numpy(), dtype = jnp.float32)\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-28T07:28:54.038648Z","iopub.execute_input":"2023-11-28T07:28:54.038955Z","iopub.status.idle":"2023-11-28T07:28:54.636366Z","shell.execute_reply.started":"2023-11-28T07:28:54.038931Z","shell.execute_reply":"2023-11-28T07:28:54.635511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"W = jnp.zeros(X_train.shape[1:])\n\nb = 0.\n\nlr = 0.01\n\nn_iter = 500","metadata":{"execution":{"iopub.status.busy":"2023-11-28T07:28:54.637314Z","iopub.execute_input":"2023-11-28T07:28:54.637578Z","iopub.status.idle":"2023-11-28T07:28:58.019911Z","shell.execute_reply.started":"2023-11-28T07:28:54.637555Z","shell.execute_reply":"2023-11-28T07:28:58.019090Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_y(W, b, X):\n    return jnp.dot(X, W) + b","metadata":{"execution":{"iopub.status.busy":"2023-11-28T07:28:58.021167Z","iopub.execute_input":"2023-11-28T07:28:58.021480Z","iopub.status.idle":"2023-11-28T07:28:58.026036Z","shell.execute_reply.started":"2023-11-28T07:28:58.021452Z","shell.execute_reply":"2023-11-28T07:28:58.025009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def loss_fn(W, b, X, y):\n    error = predict_y(W, b, X) - y\n    return jnp.mean(jnp.square(error))","metadata":{"execution":{"iopub.status.busy":"2023-11-28T07:28:58.027278Z","iopub.execute_input":"2023-11-28T07:28:58.027595Z","iopub.status.idle":"2023-11-28T07:28:58.036317Z","shell.execute_reply.started":"2023-11-28T07:28:58.027569Z","shell.execute_reply":"2023-11-28T07:28:58.035457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def update_W(W, b, X, y, lr):\n    grad_W = grad(loss_fn, argnums = 0)(W, b, X, y)\n    \n    return tree_map(lambda W, graad_W, lr : W - lr*grad_W, W, grad_W, lr)\n    \ndef update_b(W, b, X, y, lr):    \n    grad_b = grad(loss_fn, argnums = 1)(W, b, X, y)\n    \n    return tree_map(lambda b, graad_b, lr : b - lr*grad_b, b, grad_b, lr)","metadata":{"execution":{"iopub.status.busy":"2023-11-28T07:28:58.037612Z","iopub.execute_input":"2023-11-28T07:28:58.037924Z","iopub.status.idle":"2023-11-28T07:28:58.045080Z","shell.execute_reply.started":"2023-11-28T07:28:58.037892Z","shell.execute_reply":"2023-11-28T07:28:58.044033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_hist = []\n\nfor i in range(n_iter):\n    loss = loss_fn(W,b, X_train, y_train)\n    \n    if (i + 1) % 100 == 0:\n        print ('Iteration', i+1, 'Loss:', loss)\n        \n    loss_hist.append(loss)\n    \n    W = jit(update_W)(W, b, X_train, y_train, lr)\n    b = jit(update_b)(W, b, X_train, y_train, lr)    ","metadata":{"execution":{"iopub.status.busy":"2023-11-28T07:28:58.046362Z","iopub.execute_input":"2023-11-28T07:28:58.046971Z","iopub.status.idle":"2023-11-28T07:28:59.226006Z","shell.execute_reply.started":"2023-11-28T07:28:58.046934Z","shell.execute_reply":"2023-11-28T07:28:59.224942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_, ax = plt.subplots(figsize = (12,8))\n    \nax.set(xlabel = 'Iteration', ylabel = 'Loss', title = 'Training Loss per Epoch')\nplt.plot(loss_hist)   ","metadata":{"execution":{"iopub.status.busy":"2023-11-28T07:28:59.227330Z","iopub.execute_input":"2023-11-28T07:28:59.227668Z","iopub.status.idle":"2023-11-28T07:28:59.642424Z","shell.execute_reply.started":"2023-11-28T07:28:59.227640Z","shell.execute_reply":"2023-11-28T07:28:59.641539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = predict_y(W, b, X_test)","metadata":{"execution":{"iopub.status.busy":"2023-11-28T07:28:59.643763Z","iopub.execute_input":"2023-11-28T07:28:59.644335Z","iopub.status.idle":"2023-11-28T07:28:59.807234Z","shell.execute_reply.started":"2023-11-28T07:28:59.644300Z","shell.execute_reply":"2023-11-28T07:28:59.806362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Test Score: ', r2_score(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-11-28T07:28:59.808666Z","iopub.execute_input":"2023-11-28T07:28:59.809511Z","iopub.status.idle":"2023-11-28T07:28:59.816256Z","shell.execute_reply.started":"2023-11-28T07:28:59.809473Z","shell.execute_reply":"2023-11-28T07:28:59.815283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ll_distance(x, y):\n    assert x.ndim == y.ndim == 1\n    return jnp.sum(jnp.abs(x - y))","metadata":{"execution":{"iopub.status.busy":"2023-11-28T07:28:59.817790Z","iopub.execute_input":"2023-11-28T07:28:59.818101Z","iopub.status.idle":"2023-11-28T07:28:59.825620Z","shell.execute_reply.started":"2023-11-28T07:28:59.818073Z","shell.execute_reply":"2023-11-28T07:28:59.824543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xs = jax.random.normal(jax.random.PRNGKey(0), (100, 3))","metadata":{"execution":{"iopub.status.busy":"2023-11-28T07:28:59.827048Z","iopub.execute_input":"2023-11-28T07:28:59.827672Z","iopub.status.idle":"2023-11-28T07:29:00.071459Z","shell.execute_reply.started":"2023-11-28T07:28:59.827635Z","shell.execute_reply":"2023-11-28T07:29:00.070450Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(xs)","metadata":{"execution":{"iopub.status.busy":"2023-11-28T07:29:00.072731Z","iopub.execute_input":"2023-11-28T07:29:00.073037Z","iopub.status.idle":"2023-11-28T07:29:00.081597Z","shell.execute_reply.started":"2023-11-28T07:29:00.073011Z","shell.execute_reply":"2023-11-28T07:29:00.080734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pairwise_distances(dist, xs):\n    return jax.vmap(jax.vmap(dist, (0, None)), (None, 0))(xs, xs)\n\nys = pairwise_distances(ll_distance, xs)\nprint(ys[0])","metadata":{"execution":{"iopub.status.busy":"2023-11-28T07:29:00.083046Z","iopub.execute_input":"2023-11-28T07:29:00.083960Z","iopub.status.idle":"2023-11-28T07:29:00.692178Z","shell.execute_reply.started":"2023-11-28T07:29:00.083933Z","shell.execute_reply":"2023-11-28T07:29:00.691020Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow_datasets as tfds","metadata":{"execution":{"iopub.status.busy":"2023-11-28T07:29:00.693470Z","iopub.execute_input":"2023-11-28T07:29:00.693809Z","iopub.status.idle":"2023-11-28T07:29:08.416217Z","shell.execute_reply.started":"2023-11-28T07:29:00.693778Z","shell.execute_reply":"2023-11-28T07:29:08.415237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_split = 0.2\nbatch_size = 64\n\n(full_train_set, test_dataset), ds_info = tfds.load(\n    'cifar10',\n    split=['train', 'test'],\n    shuffle_files=True,\n    as_supervised=True,\n    with_info=True,\n)\n\n\n# Similarly, we apply the same transforms to the\n# validation and test dataset","metadata":{"execution":{"iopub.status.busy":"2023-11-28T07:29:08.417521Z","iopub.execute_input":"2023-11-28T07:29:08.418089Z","iopub.status.idle":"2023-11-28T07:30:07.293339Z","shell.execute_reply.started":"2023-11-28T07:29:08.418061Z","shell.execute_reply":"2023-11-28T07:30:07.292459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def normalize_img(image, label):\n    image = tf.cast(image, tf.float32) / 255.\n    return image, label\n\nfull_train_set = full_train_set.map(\n    normalize_img, num_parallel_calls=tf.data.AUTOTUNE\n)\n\nnum_data = tf.data.experimental.cardinality(\n    full_train_set\n).numpy()\nprint(\"Total number of data points:\", num_data)\ntrain_dataset = full_train_set.take(\n    num_data * (1 - validation_split)\n)\nval_dataset = full_train_set.take(\n    num_data * (validation_split)\n)\nprint(\n    \"Number of train data points:\",\n    tf.data.experimental.cardinality(train_dataset).numpy()\n)\nprint(\n    \"Number of val data points:\",\n    tf.data.experimental.cardinality(val_dataset).numpy()\n)\n\ntrain_dataset = train_dataset.cache()\ntrain_dataset = train_dataset.shuffle(\n    tf.data.experimental.cardinality(train_dataset).numpy()\n)\ntrain_dataset = train_dataset.batch(batch_size)\n\nval_dataset = val_dataset.cache()\nval_dataset = val_dataset.shuffle(\n    tf.data.experimental.cardinality(val_dataset).numpy()\n)\nval_dataset = val_dataset.batch(batch_size)\n\n\ntest_dataset = test_dataset.map(\n    normalize_img, num_parallel_calls=tf.data.AUTOTUNE\n)\nprint(\n    \"Number of test data points:\",\n    tf.data.experimental.cardinality(test_dataset).numpy()\n    )\ntest_dataset = test_dataset.cache()\ntest_dataset = test_dataset.batch(batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-11-28T07:30:07.294446Z","iopub.execute_input":"2023-11-28T07:30:07.294759Z","iopub.status.idle":"2023-11-28T07:30:07.382051Z","shell.execute_reply.started":"2023-11-28T07:30:07.294733Z","shell.execute_reply":"2023-11-28T07:30:07.381241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_datagen = iter(tfds.as_numpy(train_dataset))\nnext(train_datagen)[1]","metadata":{"execution":{"iopub.status.busy":"2023-11-28T07:30:07.383069Z","iopub.execute_input":"2023-11-28T07:30:07.383326Z","iopub.status.idle":"2023-11-28T07:30:10.445541Z","shell.execute_reply.started":"2023-11-28T07:30:07.383302Z","shell.execute_reply":"2023-11-28T07:30:10.444522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds_info","metadata":{"execution":{"iopub.status.busy":"2023-11-28T07:30:10.447227Z","iopub.execute_input":"2023-11-28T07:30:10.448037Z","iopub.status.idle":"2023-11-28T07:30:10.454428Z","shell.execute_reply.started":"2023-11-28T07:30:10.447999Z","shell.execute_reply":"2023-11-28T07:30:10.453326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# WandB Tut","metadata":{}},{"cell_type":"code","source":"seed = 42\npooling = \"avg\"\nbatch_size = 4\n\nMODULE_DICT = {\n    \"avg\": nn.avg_pool,\n    \"max\": nn.max_pool,\n}","metadata":{"execution":{"iopub.status.busy":"2023-11-28T09:43:04.524220Z","iopub.execute_input":"2023-11-28T09:43:04.525116Z","iopub.status.idle":"2023-11-28T09:43:04.529766Z","shell.execute_reply.started":"2023-11-28T09:43:04.525075Z","shell.execute_reply":"2023-11-28T09:43:04.528701Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"class CNN(nn.Module):\n    pool_module: Callable = nn.avg_pool\n\n\n    def setup(self):\n        self.conv_1 = nn.Conv(features=32, kernel_size=(3, 3))\n        self.conv_2 = nn.Conv(features=32, kernel_size=(3, 3))\n        self.conv_3 = nn.Conv(features=64, kernel_size=(3, 3))\n        self.conv_4 = nn.Conv(features=64, kernel_size=(3, 3))\n        self.conv_5 = nn.Conv(features=128, kernel_size=(3, 3))\n        self.conv_6 = nn.Conv(features=128, kernel_size=(3, 3))\n        self.dense_1 = nn.Dense(features=1024)\n        self.dense_2 = nn.Dense(features=512)\n        self.dense_output = nn.Dense(features=10)\n\n\n    @nn.compact\n    def __call__(self, x):\n        x = nn.relu(self.conv_1(x))\n        x = nn.relu(self.conv_2(x))\n        x = self.pool_module(x, window_shape=(2, 2), strides=(2, 2))\n        x = nn.relu(self.conv_3(x))\n        x = nn.relu(self.conv_4(x))\n        x = self.pool_module(x, window_shape=(2, 2), strides=(2, 2))\n        x = nn.relu(self.conv_5(x))\n        x = nn.relu(self.conv_6(x))\n        x = self.pool_module(x, window_shape=(2, 2), strides=(2, 2))\n        x = x.reshape((x.shape[0], -1))\n        x = nn.relu(self.dense_1(x))\n        x = nn.relu(self.dense_2(x))\n        return self.dense_output(x)\n\n#     @nn.compact\n#     def __call__(self, x):\n#         x = nn.relu(nn.Conv(features=32, kernel_size=(3, 3))(x))\n#         x = nn.relu(nn.Conv(features=32, kernel_size=(3, 3))(x))\n#         x = self.pool_module(x, window_shape=(2, 2), strides=(2, 2))\n#         x = nn.relu(nn.Conv(features=64, kernel_size=(3, 3))(x))\n#         x = nn.relu(nn.Conv(features=64, kernel_size=(3, 3))(x))\n#         x = self.pool_module(x, window_shape=(2, 2), strides=(2, 2))\n#         x = nn.relu(nn.Conv(features=128, kernel_size=(3, 3))(x))\n#         x = nn.relu(nn.Conv(features=128, kernel_size=(3, 3))(x))\n#         x = self.pool_module(x, window_shape=(2, 2), strides=(2, 2))\n#         x = x.reshape((x.shape[0], -1))\n#         x = nn.relu(nn.Dense(features=1024)(x))\n#         x = nn.relu(nn.Dense(features=512)(x))\n#         return nn.Dense(features=10)(x)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-28T09:43:06.913338Z","iopub.execute_input":"2023-11-28T09:43:06.914106Z","iopub.status.idle":"2023-11-28T09:43:06.927217Z","shell.execute_reply.started":"2023-11-28T09:43:06.914059Z","shell.execute_reply":"2023-11-28T09:43:06.926069Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"rng = jax.random.PRNGKey(seed) # PRNG Key\nx = jnp.ones(shape=(batch_size, 32, 32, 3)) # Dummy Input\nmodel = CNN(pool_module=MODULE_DICT[pooling]) # Instantiate the Model\nparams = model.init(rng, x) # Initialize the parameters\njax.tree_map(lambda x: x.shape, params) # Check the parameters","metadata":{"execution":{"iopub.status.busy":"2023-11-28T09:43:09.424542Z","iopub.execute_input":"2023-11-28T09:43:09.425286Z","iopub.status.idle":"2023-11-28T09:43:13.297968Z","shell.execute_reply.started":"2023-11-28T09:43:09.425251Z","shell.execute_reply":"2023-11-28T09:43:13.296793Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"2023-11-28 09:43:09.463798: E external/xla/xla/pjrt/pjrt_stream_executor_client.cc:2461] Execution of replica 0 failed: INTERNAL: Failed to load in-memory CUBIN (compiled for a different GPU?).: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m2\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1 \u001b[0mrng = jax.random.PRNGKey(seed) \u001b[2m# PRNG Key\u001b[0m                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2 x = jnp.ones(shape=(batch_size, \u001b[94m32\u001b[0m, \u001b[94m32\u001b[0m, \u001b[94m3\u001b[0m)) \u001b[2m# Dummy Input\u001b[0m                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m3 \u001b[0mmodel = CNN(pool_module=MODULE_DICT[pooling]) \u001b[2m# Instantiate the Model\u001b[0m                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m4 \u001b[0mparams = model.init(rng, x) \u001b[2m# Initialize the parameters\u001b[0m                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m5 \u001b[0mjax.tree_map(\u001b[94mlambda\u001b[0m x: x.shape, params) \u001b[2m# Check the parameters\u001b[0m                               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/jax/_src/numpy/\u001b[0m\u001b[1;33mlax_numpy.py\u001b[0m:\u001b[94m2161\u001b[0m in \u001b[92mones\u001b[0m                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2158 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mTypeError\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33mexpected sequence object with len >= 0 or a single integer\u001b[0m\u001b[33m\"\u001b[0m)         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2159 \u001b[0m\u001b[2m  \u001b[0mshape = canonicalize_shape(shape)                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2160 \u001b[0m\u001b[2m  \u001b[0mdtypes.check_user_dtype_supported(dtype, \u001b[33m\"\u001b[0m\u001b[33mones\u001b[0m\u001b[33m\"\u001b[0m)                                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2161 \u001b[2m  \u001b[0m\u001b[94mreturn\u001b[0m lax.full(shape, \u001b[94m1\u001b[0m, _jnp_dtype(dtype))                                            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2162 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2163 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2164 \u001b[0m\u001b[1;95m@util\u001b[0m._wraps(np.empty, lax_description=\u001b[33m\"\"\"\u001b[0m\u001b[33m\\\u001b[0m                                               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/jax/_src/lax/\u001b[0m\u001b[1;33mlax.py\u001b[0m:\u001b[94m1206\u001b[0m in \u001b[92mfull\u001b[0m                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1203 \u001b[0m\u001b[2m  \u001b[0mweak_type = dtype \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mand\u001b[0m dtypes.is_weakly_typed(fill_value)                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1204 \u001b[0m\u001b[2m  \u001b[0mdtype = dtypes.canonicalize_dtype(dtype \u001b[95mor\u001b[0m _dtype(fill_value))                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1205 \u001b[0m\u001b[2m  \u001b[0mfill_value = _convert_element_type(fill_value, dtype, weak_type)                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1206 \u001b[2m  \u001b[0m\u001b[94mreturn\u001b[0m broadcast(fill_value, shape)                                                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1207 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1208 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mzeros_like_shaped_array\u001b[0m(aval: ShapedArray) -> Array:                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1209 \u001b[0m\u001b[2m  \u001b[0m\u001b[94massert\u001b[0m \u001b[96misinstance\u001b[0m(aval, ShapedArray)                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/jax/_src/lax/\u001b[0m\u001b[1;33mlax.py\u001b[0m:\u001b[94m768\u001b[0m in \u001b[92mbroadcast\u001b[0m                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 765 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33mjax.lax.broadcast_in_dim : add new dimensions at any location in the array shape.\u001b[0m     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 766 \u001b[0m\u001b[2;33m  \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 767 \u001b[0m\u001b[2m  \u001b[0mdims = \u001b[96mtuple\u001b[0m(\u001b[96mrange\u001b[0m(\u001b[96mlen\u001b[0m(sizes), \u001b[96mlen\u001b[0m(sizes) + np.ndim(operand)))                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 768 \u001b[2m  \u001b[0m\u001b[94mreturn\u001b[0m broadcast_in_dim(operand, \u001b[96mtuple\u001b[0m(sizes) + np.shape(operand), dims)                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 769 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 770 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mbroadcast_in_dim\u001b[0m(operand: ArrayLike, shape: Shape,                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 771 \u001b[0m\u001b[2m│   │   │   │   │    \u001b[0mbroadcast_dimensions: Sequence[\u001b[96mint\u001b[0m]) -> Array:                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/jax/_src/lax/\u001b[0m\u001b[1;33mlax.py\u001b[0m:\u001b[94m797\u001b[0m in \u001b[92mbroadcast_in_dim\u001b[0m              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 794 \u001b[0m\u001b[2m│   \u001b[0mdyn_shape, static_shape = _extract_tracers_dyn_shape(shape)                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 795 \u001b[0m\u001b[2m  \u001b[0m\u001b[94melse\u001b[0m:                                                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 796 \u001b[0m\u001b[2m│   \u001b[0mdyn_shape, static_shape = [], shape  \u001b[2m# type: ignore\u001b[0m                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 797 \u001b[2m  \u001b[0m\u001b[94mreturn\u001b[0m broadcast_in_dim_p.bind(                                                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 798 \u001b[0m\u001b[2m│     \u001b[0moperand, *dyn_shape, shape=\u001b[96mtuple\u001b[0m(static_shape),                                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 799 \u001b[0m\u001b[2m│     \u001b[0mbroadcast_dimensions=\u001b[96mtuple\u001b[0m(broadcast_dimensions))                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 800 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/jax/_src/\u001b[0m\u001b[1;33mcore.py\u001b[0m:\u001b[94m380\u001b[0m in \u001b[92mbind\u001b[0m                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 377 \u001b[0m\u001b[2m  \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mbind\u001b[0m(\u001b[96mself\u001b[0m, *args, **params):                                                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 378 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94massert\u001b[0m (\u001b[95mnot\u001b[0m config.jax_enable_checks \u001b[95mor\u001b[0m                                               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 379 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mall\u001b[0m(\u001b[96misinstance\u001b[0m(arg, Tracer) \u001b[95mor\u001b[0m valid_jaxtype(arg) \u001b[94mfor\u001b[0m arg \u001b[95min\u001b[0m args)), args     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 380 \u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.bind_with_trace(find_top_trace(args), args, params)                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 381 \u001b[0m\u001b[2m  \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 382 \u001b[0m\u001b[2m  \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mbind_with_trace\u001b[0m(\u001b[96mself\u001b[0m, trace, args, params):                                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 383 \u001b[0m\u001b[2m│   \u001b[0mout = trace.process_primitive(\u001b[96mself\u001b[0m, \u001b[96mmap\u001b[0m(trace.full_raise, args), params)              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/jax/_src/\u001b[0m\u001b[1;33mcore.py\u001b[0m:\u001b[94m383\u001b[0m in \u001b[92mbind_with_trace\u001b[0m                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 380 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.bind_with_trace(find_top_trace(args), args, params)                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 381 \u001b[0m\u001b[2m  \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 382 \u001b[0m\u001b[2m  \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mbind_with_trace\u001b[0m(\u001b[96mself\u001b[0m, trace, args, params):                                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 383 \u001b[2m│   \u001b[0mout = trace.process_primitive(\u001b[96mself\u001b[0m, \u001b[96mmap\u001b[0m(trace.full_raise, args), params)              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 384 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mmap\u001b[0m(full_lower, out) \u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.multiple_results \u001b[94melse\u001b[0m full_lower(out)             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 385 \u001b[0m\u001b[2m  \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 386 \u001b[0m\u001b[2m  \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mdef_impl\u001b[0m(\u001b[96mself\u001b[0m, impl):                                                               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/jax/_src/\u001b[0m\u001b[1;33mcore.py\u001b[0m:\u001b[94m815\u001b[0m in \u001b[92mprocess_primitive\u001b[0m                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 812 \u001b[0m\u001b[2m  \u001b[0mlift = sublift = pure                                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 813 \u001b[0m\u001b[2m  \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 814 \u001b[0m\u001b[2m  \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mprocess_primitive\u001b[0m(\u001b[96mself\u001b[0m, primitive, tracers, params):                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 815 \u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m primitive.impl(*tracers, **params)                                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 816 \u001b[0m\u001b[2m  \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 817 \u001b[0m\u001b[2m  \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mprocess_call\u001b[0m(\u001b[96mself\u001b[0m, primitive, f, tracers, params):                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 818 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m primitive.impl(f, *tracers, **params)                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/jax/_src/\u001b[0m\u001b[1;33mdispatch.py\u001b[0m:\u001b[94m144\u001b[0m in \u001b[92mapply_primitive\u001b[0m              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m141 \u001b[0m\u001b[2m│   │   \u001b[0mprim.name, fails, args, \u001b[33m'\u001b[0m\u001b[33mjit\u001b[0m\u001b[33m'\u001b[0m, arg_names)                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m142 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mValueError\u001b[0m(msg) \u001b[94mfrom\u001b[0m \u001b[94mNone\u001b[0m                                                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m143 \u001b[0m\u001b[2m  \u001b[0m                                                                                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m144 \u001b[2m  \u001b[0m\u001b[94mreturn\u001b[0m compiled_fun(*args)                                                               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m145 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m146 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m147 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92msimple_impl\u001b[0m(prim):                                                                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/jax/_src/\u001b[0m\u001b[1;33mdispatch.py\u001b[0m:\u001b[94m227\u001b[0m in \u001b[92m<lambda>\u001b[0m                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m224 \u001b[0m\u001b[2m│     \u001b[0mlu.wrap_init(prim_fun), prim.name, donated_invars, \u001b[94mFalse\u001b[0m, in_avals,                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m225 \u001b[0m\u001b[2m│     \u001b[0morig_in_shardings)                                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m226 \u001b[0m\u001b[2m  \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m prim.multiple_results:                                                            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m227 \u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[94mlambda\u001b[0m *args, **kw: compiled(*args, **kw)[\u001b[94m0\u001b[0m]                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m228 \u001b[0m\u001b[2m  \u001b[0m\u001b[94melse\u001b[0m:                                                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m229 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m compiled                                                                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m230 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/jax/_src/\u001b[0m\u001b[1;33mprofiler.py\u001b[0m:\u001b[94m314\u001b[0m in \u001b[92mwrapper\u001b[0m                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m311 \u001b[0m\u001b[2m  \u001b[0m\u001b[1;95m@wraps\u001b[0m(func)                                                                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m312 \u001b[0m\u001b[2m  \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mwrapper\u001b[0m(*args, **kwargs):                                                            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m313 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mwith\u001b[0m TraceAnnotation(name, **decorator_kwargs):                                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m314 \u001b[2m│     \u001b[0m\u001b[94mreturn\u001b[0m func(*args, **kwargs)                                                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m315 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m wrapper                                                                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m316 \u001b[0m\u001b[2m  \u001b[0m\u001b[94mreturn\u001b[0m wrapper                                                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m317 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/jax/_src/interpreters/\u001b[0m\u001b[1;33mpxla.py\u001b[0m:\u001b[94m1349\u001b[0m in \u001b[92m__call__\u001b[0m           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1346 \u001b[0m\u001b[2m│   │   │     \u001b[0m\u001b[96mlen\u001b[0m(\u001b[96mself\u001b[0m.ordered_effects)),                                                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1347 \u001b[0m\u001b[2m│   │     \u001b[0mresults.consume_token())                                                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1348 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melse\u001b[0m:                                                                                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1349 \u001b[2m│     \u001b[0mresults = \u001b[96mself\u001b[0m.xla_executable.execute_sharded(input_bufs)                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1350 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m dispatch.needs_check_special():                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1351 \u001b[0m\u001b[2m│     \u001b[0mout_arrays = results.disassemble_into_single_device_arrays()                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1352 \u001b[0m\u001b[2m│     \u001b[0m\u001b[94mfor\u001b[0m arrays \u001b[95min\u001b[0m out_arrays:                                                           \u001b[31m│\u001b[0m\n\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n\u001b[1;91mXlaRuntimeError: \u001b[0mINTERNAL: Failed to load in-memory CUBIN \u001b[1m(\u001b[0mcompiled for a different GPU?\u001b[1m)\u001b[0m.: \nCUDA_ERROR_OUT_OF_MEMORY: out of memory\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1 </span>rng = jax.random.PRNGKey(seed) <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># PRNG Key</span>                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2 x = jnp.ones(shape=(batch_size, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">32</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">32</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span>)) <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Dummy Input</span>                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3 </span>model = CNN(pool_module=MODULE_DICT[pooling]) <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Instantiate the Model</span>                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4 </span>params = model.init(rng, x) <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Initialize the parameters</span>                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5 </span>jax.tree_map(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">lambda</span> x: x.shape, params) <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Check the parameters</span>                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/jax/_src/numpy/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">lax_numpy.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2161</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">ones</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2158 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">TypeError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">\"expected sequence object with len &gt;= 0 or a single integer\"</span>)         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2159 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  </span>shape = canonicalize_shape(shape)                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2160 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  </span>dtypes.check_user_dtype_supported(dtype, <span style=\"color: #808000; text-decoration-color: #808000\">\"ones\"</span>)                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2161 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> lax.full(shape, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>, _jnp_dtype(dtype))                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2162 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2163 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2164 </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">@util</span>._wraps(np.empty, lax_description=<span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"\\</span>                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/jax/_src/lax/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">lax.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1206</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">full</span>                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1203 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  </span>weak_type = dtype <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> dtypes.is_weakly_typed(fill_value)                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1204 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  </span>dtype = dtypes.canonicalize_dtype(dtype <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _dtype(fill_value))                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1205 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  </span>fill_value = _convert_element_type(fill_value, dtype, weak_type)                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1206 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> broadcast(fill_value, shape)                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1207 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1208 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">zeros_like_shaped_array</span>(aval: ShapedArray) -&gt; Array:                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1209 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">assert</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(aval, ShapedArray)                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/jax/_src/lax/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">lax.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">768</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">broadcast</span>                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 765 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">jax.lax.broadcast_in_dim : add new dimensions at any location in the array shape.</span>     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 766 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">  </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 767 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  </span>dims = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">tuple</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">range</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(sizes), <span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(sizes) + np.ndim(operand)))                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 768 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> broadcast_in_dim(operand, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">tuple</span>(sizes) + np.shape(operand), dims)                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 769 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 770 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">broadcast_in_dim</span>(operand: ArrayLike, shape: Shape,                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 771 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │    </span>broadcast_dimensions: Sequence[<span style=\"color: #00ffff; text-decoration-color: #00ffff\">int</span>]) -&gt; Array:                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/jax/_src/lax/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">lax.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">797</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">broadcast_in_dim</span>              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 794 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>dyn_shape, static_shape = _extract_tracers_dyn_shape(shape)                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 795 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 796 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>dyn_shape, static_shape = [], shape  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># type: ignore</span>                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 797 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> broadcast_in_dim_p.bind(                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 798 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│     </span>operand, *dyn_shape, shape=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">tuple</span>(static_shape),                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 799 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│     </span>broadcast_dimensions=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">tuple</span>(broadcast_dimensions))                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 800 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/jax/_src/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">core.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">380</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">bind</span>                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 377 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">bind</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, *args, **params):                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 378 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">assert</span> (<span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> config.jax_enable_checks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span>                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 379 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">all</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(arg, Tracer) <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> valid_jaxtype(arg) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> arg <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> args)), args     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 380 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.bind_with_trace(find_top_trace(args), args, params)                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 381 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 382 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">bind_with_trace</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, trace, args, params):                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 383 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>out = trace.process_primitive(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">map</span>(trace.full_raise, args), params)              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/jax/_src/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">core.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">383</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">bind_with_trace</span>                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 380 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.bind_with_trace(find_top_trace(args), args, params)                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 381 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 382 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">bind_with_trace</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, trace, args, params):                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 383 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>out = trace.process_primitive(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">map</span>(trace.full_raise, args), params)              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 384 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">map</span>(full_lower, out) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.multiple_results <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> full_lower(out)             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 385 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 386 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">def_impl</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, impl):                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/jax/_src/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">core.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">815</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">process_primitive</span>                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 812 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  </span>lift = sublift = pure                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 813 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 814 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">process_primitive</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, primitive, tracers, params):                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 815 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> primitive.impl(*tracers, **params)                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 816 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 817 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">process_call</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, primitive, f, tracers, params):                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 818 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> primitive.impl(f, *tracers, **params)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/jax/_src/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">dispatch.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">144</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">apply_primitive</span>              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">141 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>prim.name, fails, args, <span style=\"color: #808000; text-decoration-color: #808000\">'jit'</span>, arg_names)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">142 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ValueError</span>(msg) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">143 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  </span>                                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>144 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> compiled_fun(*args)                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">145 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">146 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">147 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">simple_impl</span>(prim):                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/jax/_src/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">dispatch.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">227</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;lambda&gt;</span>                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">224 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│     </span>lu.wrap_init(prim_fun), prim.name, donated_invars, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>, in_avals,                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">225 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│     </span>orig_in_shardings)                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">226 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> prim.multiple_results:                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>227 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">lambda</span> *args, **kw: compiled(*args, **kw)[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>]                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">228 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">229 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> compiled                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">230 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/jax/_src/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">profiler.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">314</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">wrapper</span>                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">311 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">@wraps</span>(func)                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">312 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">wrapper</span>(*args, **kwargs):                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">313 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> TraceAnnotation(name, **decorator_kwargs):                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>314 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│     </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> func(*args, **kwargs)                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">315 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> wrapper                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">316 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> wrapper                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">317 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/jax/_src/interpreters/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">pxla.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1349</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__call__</span>           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1346 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │     </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.ordered_effects)),                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1347 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │     </span>results.consume_token())                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1348 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1349 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│     </span>results = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.xla_executable.execute_sharded(input_bufs)                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1350 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> dispatch.needs_check_special():                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1351 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│     </span>out_arrays = results.disassemble_into_single_device_arrays()                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1352 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│     </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> arrays <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> out_arrays:                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">XlaRuntimeError: </span>INTERNAL: Failed to load in-memory CUBIN <span style=\"font-weight: bold\">(</span>compiled for a different GPU?<span style=\"font-weight: bold\">)</span>.: \nCUDA_ERROR_OUT_OF_MEMORY: out of memory\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"type(params['params'].keys())","metadata":{"execution":{"iopub.status.busy":"2023-11-28T07:30:19.660694Z","iopub.execute_input":"2023-11-28T07:30:19.661332Z","iopub.status.idle":"2023-11-28T07:30:19.667558Z","shell.execute_reply.started":"2023-11-28T07:30:19.661295Z","shell.execute_reply":"2023-11-28T07:30:19.666443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.data.experimental.cardinality(train_dataset).numpy()","metadata":{"execution":{"iopub.status.busy":"2023-11-28T07:30:19.669061Z","iopub.execute_input":"2023-11-28T07:30:19.669363Z","iopub.status.idle":"2023-11-28T07:30:19.679220Z","shell.execute_reply.started":"2023-11-28T07:30:19.669337Z","shell.execute_reply":"2023-11-28T07:30:19.678362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def init_train_state(\n    model, random_key, shape, learning_rate\n) -> train_state.TrainState:\n    # Initialize the Model\n    variables = model.init(random_key, jnp.ones(shape))\n    # Create the optimizer\n    optimizer = optax.adam(learning_rate)\n    # Create a State\n    return train_state.TrainState.create(\n        apply_fn = model.apply,\n        tx=optimizer,\n        params=variables['params']\n    )\n\n\nlearning_rate = 0.01\n\nstate = init_train_state(\n    model, rng, (batch_size, 32, 32, 3), learning_rate\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-28T07:30:19.680387Z","iopub.execute_input":"2023-11-28T07:30:19.681626Z","iopub.status.idle":"2023-11-28T07:30:20.223568Z","shell.execute_reply.started":"2023-11-28T07:30:19.681597Z","shell.execute_reply":"2023-11-28T07:30:20.222582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"next(iter(tfds.as_numpy(train_dataset)))[0][0].shape","metadata":{"execution":{"iopub.status.busy":"2023-11-28T07:30:20.224750Z","iopub.execute_input":"2023-11-28T07:30:20.225059Z","iopub.status.idle":"2023-11-28T07:30:20.299118Z","shell.execute_reply.started":"2023-11-28T07:30:20.225031Z","shell.execute_reply":"2023-11-28T07:30:20.298159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.apply(params, next(iter(tfds.as_numpy(train_dataset)))[0][0].reshape(1,32,32,3))\nnew_state = state = init_train_state(\n    model, rng, (1, 32, 32, 3), learning_rate\n)\n\nnew_state.apply_fn({'params': new_state.params}, next(iter(tfds.as_numpy(train_dataset)))[0][0].reshape(1,32,32,3))","metadata":{"execution":{"iopub.status.busy":"2023-11-28T07:30:20.300288Z","iopub.execute_input":"2023-11-28T07:30:20.300596Z","iopub.status.idle":"2023-11-28T07:30:23.243176Z","shell.execute_reply.started":"2023-11-28T07:30:20.300570Z","shell.execute_reply":"2023-11-28T07:30:23.242234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params.keys()","metadata":{"execution":{"iopub.status.busy":"2023-11-28T07:30:23.244319Z","iopub.execute_input":"2023-11-28T07:30:23.244647Z","iopub.status.idle":"2023-11-28T07:30:23.250632Z","shell.execute_reply.started":"2023-11-28T07:30:23.244620Z","shell.execute_reply":"2023-11-28T07:30:23.249737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params['params']['conv_1']['kernel'].shape","metadata":{"execution":{"iopub.status.busy":"2023-11-28T07:30:23.251968Z","iopub.execute_input":"2023-11-28T07:30:23.252280Z","iopub.status.idle":"2023-11-28T07:30:23.260673Z","shell.execute_reply.started":"2023-11-28T07:30:23.252254Z","shell.execute_reply":"2023-11-28T07:30:23.259746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_DEVICES = jax.device_count()\nNUM_DEVICES","metadata":{"execution":{"iopub.status.busy":"2023-11-28T07:30:23.261738Z","iopub.execute_input":"2023-11-28T07:30:23.262000Z","iopub.status.idle":"2023-11-28T07:30:23.270753Z","shell.execute_reply.started":"2023-11-28T07:30:23.261976Z","shell.execute_reply":"2023-11-28T07:30:23.269731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from jax.experimental import mesh_utils\nfrom jax.sharding import PositionalSharding","metadata":{"execution":{"iopub.status.busy":"2023-11-28T07:30:23.272029Z","iopub.execute_input":"2023-11-28T07:30:23.272798Z","iopub.status.idle":"2023-11-28T07:30:23.281782Z","shell.execute_reply.started":"2023-11-28T07:30:23.272763Z","shell.execute_reply":"2023-11-28T07:30:23.280923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = jnp.arange(64 * 64).reshape(64, 64)\njax.debug.visualize_array_sharding(x)","metadata":{"execution":{"iopub.status.busy":"2023-11-28T07:30:23.282900Z","iopub.execute_input":"2023-11-28T07:30:23.283269Z","iopub.status.idle":"2023-11-28T07:30:23.389597Z","shell.execute_reply.started":"2023-11-28T07:30:23.283230Z","shell.execute_reply":"2023-11-28T07:30:23.388632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x.sharding","metadata":{"execution":{"iopub.status.busy":"2023-11-28T07:30:23.390789Z","iopub.execute_input":"2023-11-28T07:30:23.391125Z","iopub.status.idle":"2023-11-28T07:30:23.397535Z","shell.execute_reply.started":"2023-11-28T07:30:23.391096Z","shell.execute_reply":"2023-11-28T07:30:23.396514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sharding = PositionalSharding(jax.local_devices())\nsharding.reshape(2, 1)","metadata":{"execution":{"iopub.status.busy":"2023-11-28T07:30:23.398820Z","iopub.execute_input":"2023-11-28T07:30:23.399184Z","iopub.status.idle":"2023-11-28T07:30:23.408495Z","shell.execute_reply.started":"2023-11-28T07:30:23.399154Z","shell.execute_reply":"2023-11-28T07:30:23.407448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = jax.device_put(x, sharding.reshape(2, 1).replicate(0))\njax.debug.visualize_array_sharding(y)","metadata":{"execution":{"iopub.status.busy":"2023-11-28T07:30:23.409791Z","iopub.execute_input":"2023-11-28T07:30:23.410100Z","iopub.status.idle":"2023-11-28T07:30:23.688581Z","shell.execute_reply.started":"2023-11-28T07:30:23.410075Z","shell.execute_reply":"2023-11-28T07:30:23.687446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t = x.reshape(64, 64)\nk = jax.device_put(t, sharding.reshape(2, 1))\nk = k.reshape(64, 8, 8, 1)\nlen(k.addressable_shards)","metadata":{"execution":{"iopub.status.busy":"2023-11-28T07:30:23.689848Z","iopub.execute_input":"2023-11-28T07:30:23.690158Z","iopub.status.idle":"2023-11-28T07:30:23.805189Z","shell.execute_reply.started":"2023-11-28T07:30:23.690133Z","shell.execute_reply":"2023-11-28T07:30:23.804174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t.reshape(8, 8, 64, 1).shape","metadata":{"execution":{"iopub.status.busy":"2023-11-28T07:30:23.806590Z","iopub.execute_input":"2023-11-28T07:30:23.806958Z","iopub.status.idle":"2023-11-28T07:30:23.834624Z","shell.execute_reply.started":"2023-11-28T07:30:23.806923Z","shell.execute_reply":"2023-11-28T07:30:23.833767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@jax.pmap\ndef g(x):\n    return x\n\np = g(t.reshape(2, 32, 64, 1))\np.sharding","metadata":{"execution":{"iopub.status.busy":"2023-11-28T07:30:23.835749Z","iopub.execute_input":"2023-11-28T07:30:23.836104Z","iopub.status.idle":"2023-11-28T07:30:23.959651Z","shell.execute_reply.started":"2023-11-28T07:30:23.836072Z","shell.execute_reply":"2023-11-28T07:30:23.958716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_ds = (jax.random.normal(jax.random.PRNGKey(1234), (1,32,32,3)).max()-jax.random.normal(jax.random.PRNGKey(1234), (1,32,32,3)))/(jax.random.normal(jax.random.PRNGKey(1234), (1,32,32,3)).max()-jax.random.normal(jax.random.PRNGKey(1234), (1,32,32,3)).min())\nnew_state.apply_fn({'params': new_state.params}, new_ds)","metadata":{"execution":{"iopub.status.busy":"2023-11-28T07:30:23.960727Z","iopub.execute_input":"2023-11-28T07:30:23.961007Z","iopub.status.idle":"2023-11-28T07:30:24.626339Z","shell.execute_reply.started":"2023-11-28T07:30:23.960985Z","shell.execute_reply":"2023-11-28T07:30:24.625411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(train_ds, test_ds), ds_info = tfds.load(\n    'mnist',\n    split=['train', 'test'],\n    shuffle_files=True,\n    as_supervised=True,\n    with_info=True,\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-28T07:30:24.627579Z","iopub.execute_input":"2023-11-28T07:30:24.627884Z","iopub.status.idle":"2023-11-28T07:30:26.331696Z","shell.execute_reply.started":"2023-11-28T07:30:24.627847Z","shell.execute_reply":"2023-11-28T07:30:26.330782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_img(img, ax=None, title=None):\n  \"\"\"Shows a single image.\"\"\"\n  if ax is None:\n    ax = plt.gca()\n  ax.imshow(img[..., 0], cmap='gray')\n  ax.set_xticks([])\n  ax.set_yticks([])\n  if title:\n    ax.set_title(title)\n\ndef show_img_grid(imgs, titles):\n  \"\"\"Shows a grid of images.\"\"\"\n  n = int(np.ceil(len(imgs)**.5))\n  _, axs = plt.subplots(n, n, figsize=(3 * n, 3 * n))\n  for i, (img, title) in enumerate(zip(imgs, titles)):\n    show_img(img, axs[i // n][i % n], title)","metadata":{"execution":{"iopub.status.busy":"2023-11-28T07:32:47.333309Z","iopub.execute_input":"2023-11-28T07:32:47.333709Z","iopub.status.idle":"2023-11-28T07:32:47.341717Z","shell.execute_reply.started":"2023-11-28T07:32:47.333678Z","shell.execute_reply":"2023-11-28T07:32:47.340669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_img_grid(\n    [next(train_ds.as_numpy_iterator())[0] for idx in range(25)],\n    [f'label={next(train_ds.as_numpy_iterator())[0][idx]}' for idx in range(25)],\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-28T07:32:47.344769Z","iopub.execute_input":"2023-11-28T07:32:47.345079Z","iopub.status.idle":"2023-11-28T07:32:50.659890Z","shell.execute_reply.started":"2023-11-28T07:32:47.345044Z","shell.execute_reply":"2023-11-28T07:32:50.658916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -qq --upgrade transformers diffusers","metadata":{"execution":{"iopub.status.busy":"2023-11-28T09:20:47.311226Z","iopub.execute_input":"2023-11-28T09:20:47.311582Z","iopub.status.idle":"2023-11-28T09:21:11.651560Z","shell.execute_reply.started":"2023-11-28T09:20:47.311549Z","shell.execute_reply":"2023-11-28T09:21:11.650018Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from diffusers import StableDiffusionXLPipeline, AutoencoderKL\nimport torch\n\nvae = AutoencoderKL.from_pretrained(\"madebyollin/sdxl-vae-fp16-fix\", torch_dtype=torch.float16)\n\npipeline = StableDiffusionXLPipeline.from_pretrained(\n    \"stabilityai/stable-diffusion-xl-base-1.0\",\n    vae=vae, torch_dtype=torch.float16,\n).to(\"cuda\")\nstyle_lora = \"johnowhitaker/lora-sdxl-njstyle\"\npipeline.load_lora_weights(style_lora)","metadata":{"execution":{"iopub.status.busy":"2023-11-28T09:21:11.654049Z","iopub.execute_input":"2023-11-28T09:21:11.654494Z","iopub.status.idle":"2023-11-28T09:22:56.914710Z","shell.execute_reply.started":"2023-11-28T09:21:11.654452Z","shell.execute_reply":"2023-11-28T09:22:56.913697Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d55fd70671f4277882779eca0147a84"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading config.json:   0%|          | 0.00/631 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bba380dfd2724c02afb4e239d62b592f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)ch_model.safetensors:   0%|          | 0.00/335M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"253fc8fde54b4cb19238819b3f907f88"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading model_index.json:   0%|          | 0.00/609 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6b4ab63a828404a86990c6a7d5503c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e9a1a3686734c8bb67b3f5a1afc5871"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cheduler_config.json:   0%|          | 0.00/479 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2407d166f110461890ffc16ad25fcd39"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer/merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6fc5fdcb1a6e4a9aa523674e232ea779"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/737 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5a098c7d1ad4cbe8b91946288f8dfe5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)ncoder_2/config.json:   0%|          | 0.00/575 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef57482c6d354b9ea322c29e5c317ca2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/472 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb6e4f6c9f9a4d7cabc40c7a7f157877"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/492M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bea7a7ae3105460d96e314c9324734f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/2.78G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab3c9746057e4efba8eec8b741229a76"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)_encoder/config.json:   0%|          | 0.00/565 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"abcdf1f13e9946b19503167e408b05fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer/vocab.json:   0%|          | 0.00/1.06M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df8da4147d464d479bcaea779623df6c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/460 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b60c64868a494711a4b46b5d4855c2e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/725 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d2ff4c95f0d409498d42e788f9874c3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading unet/config.json:   0%|          | 0.00/1.68k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7debf5fb50d745cbb1877164b33583d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)ch_model.safetensors:   0%|          | 0.00/10.3G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a47e9fe84891456988b513f00638cacd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)ch_model.safetensors:   0%|          | 0.00/335M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73a9f8fa5e624cf5bbc4785d93d2dde8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer_2/vocab.json:   0%|          | 0.00/1.06M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d049525651e84236b3492618913d6fe4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"499675bcadb94bf1942ce0315fba2f1f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)_weights.safetensors:   0%|          | 0.00/372M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6984435fae264eb7b4b22c25d490b77b"}},"metadata":{}}]},{"cell_type":"code","source":"lora_sd, alphas = pipeline.lora_state_dict(\"johnowhitaker/lora-sdxl-plushie\")\n","metadata":{"execution":{"iopub.status.busy":"2023-11-28T09:22:56.916137Z","iopub.execute_input":"2023-11-28T09:22:56.916497Z","iopub.status.idle":"2023-11-28T09:22:59.520444Z","shell.execute_reply.started":"2023-11-28T09:22:56.916460Z","shell.execute_reply":"2023-11-28T09:22:59.519436Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)_weights.safetensors:   0%|          | 0.00/372M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01cb623ba1634104995b060b1655804e"}},"metadata":{}}]},{"cell_type":"code","source":"i = 1\nfor k, v in lora_sd.items():\n    if i == 1001:\n        print(k)\n        print(v)\n        print(lora_sd[k] is v)\n        break\n        \n    i += 1","metadata":{"execution":{"iopub.status.busy":"2023-11-28T09:22:59.523135Z","iopub.execute_input":"2023-11-28T09:22:59.523432Z","iopub.status.idle":"2023-11-28T09:22:59.559882Z","shell.execute_reply.started":"2023-11-28T09:22:59.523404Z","shell.execute_reply":"2023-11-28T09:22:59.558900Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"unet.unet.up_blocks.0.attentions.2.transformer_blocks.8.attn2.to_k.lora.down.weight\ntensor([[-0.0215,  0.0165, -0.0238,  ..., -0.0112, -0.0065, -0.0004],\n        [-0.0090,  0.0174, -0.0243,  ...,  0.0274,  0.0008, -0.0087],\n        [-0.0150,  0.0116, -0.0104,  ..., -0.0006,  0.0188,  0.0111],\n        ...,\n        [-0.0003, -0.0251, -0.0076,  ..., -0.0108, -0.0131,  0.0119],\n        [ 0.0038, -0.0006,  0.0019,  ...,  0.0041,  0.0177, -0.0236],\n        [-0.0035, -0.0103,  0.0343,  ...,  0.0261, -0.0160, -0.0171]])\nTrue\n","output_type":"stream"}]},{"cell_type":"code","source":"k.split(\".lora.\")[0]","metadata":{"execution":{"iopub.status.busy":"2023-11-28T09:22:59.561062Z","iopub.execute_input":"2023-11-28T09:22:59.561432Z","iopub.status.idle":"2023-11-28T09:22:59.568555Z","shell.execute_reply.started":"2023-11-28T09:22:59.561403Z","shell.execute_reply":"2023-11-28T09:22:59.567529Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"'unet.unet.up_blocks.0.attentions.2.transformer_blocks.8.attn2.to_k'"},"metadata":{}}]},{"cell_type":"code","source":"target_layer = k.split(\".lora.\")[0]\n# target_layer = target_layer.replace(f\".0\", f\"[0]\")\nfor i in range(10):target_layer = target_layer.replace(f\".{i}\", f\"[{i}]\")\ntarget_layer[5:]","metadata":{"execution":{"iopub.status.busy":"2023-11-28T09:22:59.569999Z","iopub.execute_input":"2023-11-28T09:22:59.570366Z","iopub.status.idle":"2023-11-28T09:22:59.579294Z","shell.execute_reply.started":"2023-11-28T09:22:59.570316Z","shell.execute_reply":"2023-11-28T09:22:59.578403Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"'unet.up_blocks[0].attentions[2].transformer_blocks[8].attn2.to_k'"},"metadata":{}}]},{"cell_type":"code","source":"lora_sd['unet.unet.up_blocks.0.attentions.2.transformer_blocks.8.attn2.to_k.lora.down.weight'].numpy().shape","metadata":{"execution":{"iopub.status.busy":"2023-11-28T09:22:59.580411Z","iopub.execute_input":"2023-11-28T09:22:59.580720Z","iopub.status.idle":"2023-11-28T09:22:59.591361Z","shell.execute_reply.started":"2023-11-28T09:22:59.580694Z","shell.execute_reply":"2023-11-28T09:22:59.590530Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"(64, 2048)"},"metadata":{}}]},{"cell_type":"code","source":"eval(f\"pipeline.{target_layer[5:]}\").weight.data.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-28T09:22:59.592297Z","iopub.execute_input":"2023-11-28T09:22:59.592565Z","iopub.status.idle":"2023-11-28T09:22:59.602519Z","shell.execute_reply.started":"2023-11-28T09:22:59.592541Z","shell.execute_reply":"2023-11-28T09:22:59.601644Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"torch.Size([1280, 2048])"},"metadata":{}}]},{"cell_type":"code","source":"list(lora_sd.keys())[2:4]","metadata":{"execution":{"iopub.status.busy":"2023-11-28T09:22:59.603660Z","iopub.execute_input":"2023-11-28T09:22:59.604023Z","iopub.status.idle":"2023-11-28T09:22:59.613770Z","shell.execute_reply.started":"2023-11-28T09:22:59.603961Z","shell.execute_reply":"2023-11-28T09:22:59.612809Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"['unet.unet.down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.lora.down.weight',\n 'unet.unet.down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.lora.up.weight']"},"metadata":{}}]},{"cell_type":"code","source":"pipeline.unet.up_blocks[0].attentions[2].transformer_blocks[8].attn2.to_k.weight.data","metadata":{"execution":{"iopub.status.busy":"2023-11-28T09:22:59.616501Z","iopub.execute_input":"2023-11-28T09:22:59.616748Z","iopub.status.idle":"2023-11-28T09:22:59.672949Z","shell.execute_reply.started":"2023-11-28T09:22:59.616725Z","shell.execute_reply":"2023-11-28T09:22:59.671947Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"tensor([[ 0.0013, -0.0101,  0.0103,  ..., -0.0008,  0.0061,  0.0002],\n        [ 0.0096,  0.0074, -0.0222,  ..., -0.0037, -0.0011, -0.0003],\n        [-0.0041,  0.0070, -0.0100,  ..., -0.0049,  0.0100,  0.0035],\n        ...,\n        [-0.0035,  0.0042,  0.0114,  ...,  0.0191,  0.0088,  0.0200],\n        [-0.0049, -0.0021,  0.0037,  ..., -0.0096, -0.0137, -0.0017],\n        [-0.0037,  0.0082, -0.0078,  ...,  0.0092,  0.0126, -0.0049]],\n       device='cuda:0', dtype=torch.float16)"},"metadata":{}}]},{"cell_type":"code","source":"pipeline.vae.post_quant_conv.weight.data.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-28T10:15:29.703587Z","iopub.execute_input":"2023-11-28T10:15:29.704509Z","iopub.status.idle":"2023-11-28T10:15:29.711464Z","shell.execute_reply.started":"2023-11-28T10:15:29.704468Z","shell.execute_reply":"2023-11-28T10:15:29.710394Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"torch.Size([4, 4, 1, 1])"},"metadata":{}}]},{"cell_type":"code","source":"param_count = 0\n\ndef target_layer_from_sd_name(k):\n    # They use slightly different naming schemes for attn processors vs the rest\n    if '.processor.to_' in k:\n        target_layer = k.split(\"processor.to_\")[0] + k.split(\".processor.\")[1].split(\"_lora\")[0]\n        target_layer = target_layer.replace(\"to_out\", \"to_out[0]\")\n    else:\n        target_layer = k.split(\".lora.\")[0]\n    # Replace '.1.' with '[1]' and so on:\n    for i in range(10):target_layer = target_layer.replace(f\".{i}\", f\"[{i}]\")\n    # Return (skipping the first 'unet.' in this case):\n    return target_layer[5:]\n\nfor k, v in lora_sd.items():\n    target_layer = target_layer_from_sd_name(k)\n    aa, bb = eval(f'pipeline.{target_layer}').weight.data.shape\n    param_count += aa+bb\n    \nprint(f\"{param_count:,d}\")    ","metadata":{"execution":{"iopub.status.busy":"2023-11-28T09:22:59.681452Z","iopub.execute_input":"2023-11-28T09:22:59.681745Z","iopub.status.idle":"2023-11-28T09:22:59.756585Z","shell.execute_reply.started":"2023-11-28T09:22:59.681719Z","shell.execute_reply":"2023-11-28T09:22:59.755811Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"2,903,040\n","output_type":"stream"}]},{"cell_type":"code","source":"k","metadata":{"execution":{"iopub.status.busy":"2023-11-28T10:36:24.912058Z","iopub.execute_input":"2023-11-28T10:36:24.912614Z","iopub.status.idle":"2023-11-28T10:36:24.919810Z","shell.execute_reply.started":"2023-11-28T10:36:24.912572Z","shell.execute_reply":"2023-11-28T10:36:24.918655Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"'unet.unet.up_blocks.1.attentions.2.transformer_blocks.1.attn2.to_v.lora.up.weight'"},"metadata":{}}]},{"cell_type":"code","source":"pipeline.unet","metadata":{"execution":{"iopub.status.busy":"2023-11-28T09:22:59.777803Z","iopub.execute_input":"2023-11-28T09:22:59.778046Z","iopub.status.idle":"2023-11-28T09:22:59.820770Z","shell.execute_reply.started":"2023-11-28T09:22:59.778022Z","shell.execute_reply":"2023-11-28T09:22:59.819995Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"UNet2DConditionModel(\n  (conv_in): Conv2d(4, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (time_proj): Timesteps()\n  (time_embedding): TimestepEmbedding(\n    (linear_1): LoRACompatibleLinear(in_features=320, out_features=1280, bias=True)\n    (act): SiLU()\n    (linear_2): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n  )\n  (add_time_proj): Timesteps()\n  (add_embedding): TimestepEmbedding(\n    (linear_1): LoRACompatibleLinear(in_features=2816, out_features=1280, bias=True)\n    (act): SiLU()\n    (linear_2): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n  )\n  (down_blocks): ModuleList(\n    (0): DownBlock2D(\n      (resnets): ModuleList(\n        (0-1): 2 x ResnetBlock2D(\n          (norm1): GroupNorm(32, 320, eps=1e-05, affine=True)\n          (conv1): LoRACompatibleConv(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=320, bias=True)\n          (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): LoRACompatibleConv(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n        )\n      )\n      (downsamplers): ModuleList(\n        (0): Downsample2D(\n          (conv): LoRACompatibleConv(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n        )\n      )\n    )\n    (1): CrossAttnDownBlock2D(\n      (attentions): ModuleList(\n        (0-1): 2 x Transformer2DModel(\n          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n          (proj_in): LoRACompatibleLinear(in_features=640, out_features=640, bias=True)\n          (transformer_blocks): ModuleList(\n            (0-1): 2 x BasicTransformerBlock(\n              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n              (attn1): Attention(\n                (to_q): LoRACompatibleLinear(\n                  in_features=640, out_features=640, bias=False\n                  (lora_layer): LoRALinearLayer(\n                    (down): Linear(in_features=640, out_features=64, bias=False)\n                    (up): Linear(in_features=64, out_features=640, bias=False)\n                  )\n                )\n                (to_k): LoRACompatibleLinear(\n                  in_features=640, out_features=640, bias=False\n                  (lora_layer): LoRALinearLayer(\n                    (down): Linear(in_features=640, out_features=64, bias=False)\n                    (up): Linear(in_features=64, out_features=640, bias=False)\n                  )\n                )\n                (to_v): LoRACompatibleLinear(\n                  in_features=640, out_features=640, bias=False\n                  (lora_layer): LoRALinearLayer(\n                    (down): Linear(in_features=640, out_features=64, bias=False)\n                    (up): Linear(in_features=64, out_features=640, bias=False)\n                  )\n                )\n                (to_out): ModuleList(\n                  (0): LoRACompatibleLinear(\n                    in_features=640, out_features=640, bias=True\n                    (lora_layer): LoRALinearLayer(\n                      (down): Linear(in_features=640, out_features=64, bias=False)\n                      (up): Linear(in_features=64, out_features=640, bias=False)\n                    )\n                  )\n                  (1): Dropout(p=0.0, inplace=False)\n                )\n              )\n              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n              (attn2): Attention(\n                (to_q): LoRACompatibleLinear(\n                  in_features=640, out_features=640, bias=False\n                  (lora_layer): LoRALinearLayer(\n                    (down): Linear(in_features=640, out_features=64, bias=False)\n                    (up): Linear(in_features=64, out_features=640, bias=False)\n                  )\n                )\n                (to_k): LoRACompatibleLinear(\n                  in_features=2048, out_features=640, bias=False\n                  (lora_layer): LoRALinearLayer(\n                    (down): Linear(in_features=2048, out_features=64, bias=False)\n                    (up): Linear(in_features=64, out_features=640, bias=False)\n                  )\n                )\n                (to_v): LoRACompatibleLinear(\n                  in_features=2048, out_features=640, bias=False\n                  (lora_layer): LoRALinearLayer(\n                    (down): Linear(in_features=2048, out_features=64, bias=False)\n                    (up): Linear(in_features=64, out_features=640, bias=False)\n                  )\n                )\n                (to_out): ModuleList(\n                  (0): LoRACompatibleLinear(\n                    in_features=640, out_features=640, bias=True\n                    (lora_layer): LoRALinearLayer(\n                      (down): Linear(in_features=640, out_features=64, bias=False)\n                      (up): Linear(in_features=64, out_features=640, bias=False)\n                    )\n                  )\n                  (1): Dropout(p=0.0, inplace=False)\n                )\n              )\n              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n              (ff): FeedForward(\n                (net): ModuleList(\n                  (0): GEGLU(\n                    (proj): LoRACompatibleLinear(in_features=640, out_features=5120, bias=True)\n                  )\n                  (1): Dropout(p=0.0, inplace=False)\n                  (2): LoRACompatibleLinear(in_features=2560, out_features=640, bias=True)\n                )\n              )\n            )\n          )\n          (proj_out): LoRACompatibleLinear(in_features=640, out_features=640, bias=True)\n        )\n      )\n      (resnets): ModuleList(\n        (0): ResnetBlock2D(\n          (norm1): GroupNorm(32, 320, eps=1e-05, affine=True)\n          (conv1): LoRACompatibleConv(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=640, bias=True)\n          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n          (conv_shortcut): LoRACompatibleConv(320, 640, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (1): ResnetBlock2D(\n          (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)\n          (conv1): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=640, bias=True)\n          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n        )\n      )\n      (downsamplers): ModuleList(\n        (0): Downsample2D(\n          (conv): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n        )\n      )\n    )\n    (2): CrossAttnDownBlock2D(\n      (attentions): ModuleList(\n        (0-1): 2 x Transformer2DModel(\n          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n          (proj_in): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n          (transformer_blocks): ModuleList(\n            (0-9): 10 x BasicTransformerBlock(\n              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n              (attn1): Attention(\n                (to_q): LoRACompatibleLinear(\n                  in_features=1280, out_features=1280, bias=False\n                  (lora_layer): LoRALinearLayer(\n                    (down): Linear(in_features=1280, out_features=64, bias=False)\n                    (up): Linear(in_features=64, out_features=1280, bias=False)\n                  )\n                )\n                (to_k): LoRACompatibleLinear(\n                  in_features=1280, out_features=1280, bias=False\n                  (lora_layer): LoRALinearLayer(\n                    (down): Linear(in_features=1280, out_features=64, bias=False)\n                    (up): Linear(in_features=64, out_features=1280, bias=False)\n                  )\n                )\n                (to_v): LoRACompatibleLinear(\n                  in_features=1280, out_features=1280, bias=False\n                  (lora_layer): LoRALinearLayer(\n                    (down): Linear(in_features=1280, out_features=64, bias=False)\n                    (up): Linear(in_features=64, out_features=1280, bias=False)\n                  )\n                )\n                (to_out): ModuleList(\n                  (0): LoRACompatibleLinear(\n                    in_features=1280, out_features=1280, bias=True\n                    (lora_layer): LoRALinearLayer(\n                      (down): Linear(in_features=1280, out_features=64, bias=False)\n                      (up): Linear(in_features=64, out_features=1280, bias=False)\n                    )\n                  )\n                  (1): Dropout(p=0.0, inplace=False)\n                )\n              )\n              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n              (attn2): Attention(\n                (to_q): LoRACompatibleLinear(\n                  in_features=1280, out_features=1280, bias=False\n                  (lora_layer): LoRALinearLayer(\n                    (down): Linear(in_features=1280, out_features=64, bias=False)\n                    (up): Linear(in_features=64, out_features=1280, bias=False)\n                  )\n                )\n                (to_k): LoRACompatibleLinear(\n                  in_features=2048, out_features=1280, bias=False\n                  (lora_layer): LoRALinearLayer(\n                    (down): Linear(in_features=2048, out_features=64, bias=False)\n                    (up): Linear(in_features=64, out_features=1280, bias=False)\n                  )\n                )\n                (to_v): LoRACompatibleLinear(\n                  in_features=2048, out_features=1280, bias=False\n                  (lora_layer): LoRALinearLayer(\n                    (down): Linear(in_features=2048, out_features=64, bias=False)\n                    (up): Linear(in_features=64, out_features=1280, bias=False)\n                  )\n                )\n                (to_out): ModuleList(\n                  (0): LoRACompatibleLinear(\n                    in_features=1280, out_features=1280, bias=True\n                    (lora_layer): LoRALinearLayer(\n                      (down): Linear(in_features=1280, out_features=64, bias=False)\n                      (up): Linear(in_features=64, out_features=1280, bias=False)\n                    )\n                  )\n                  (1): Dropout(p=0.0, inplace=False)\n                )\n              )\n              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n              (ff): FeedForward(\n                (net): ModuleList(\n                  (0): GEGLU(\n                    (proj): LoRACompatibleLinear(in_features=1280, out_features=10240, bias=True)\n                  )\n                  (1): Dropout(p=0.0, inplace=False)\n                  (2): LoRACompatibleLinear(in_features=5120, out_features=1280, bias=True)\n                )\n              )\n            )\n          )\n          (proj_out): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n        )\n      )\n      (resnets): ModuleList(\n        (0): ResnetBlock2D(\n          (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)\n          (conv1): LoRACompatibleConv(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n          (conv_shortcut): LoRACompatibleConv(640, 1280, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (1): ResnetBlock2D(\n          (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n          (conv1): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n        )\n      )\n    )\n  )\n  (up_blocks): ModuleList(\n    (0): CrossAttnUpBlock2D(\n      (attentions): ModuleList(\n        (0-2): 3 x Transformer2DModel(\n          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n          (proj_in): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n          (transformer_blocks): ModuleList(\n            (0-9): 10 x BasicTransformerBlock(\n              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n              (attn1): Attention(\n                (to_q): LoRACompatibleLinear(\n                  in_features=1280, out_features=1280, bias=False\n                  (lora_layer): LoRALinearLayer(\n                    (down): Linear(in_features=1280, out_features=64, bias=False)\n                    (up): Linear(in_features=64, out_features=1280, bias=False)\n                  )\n                )\n                (to_k): LoRACompatibleLinear(\n                  in_features=1280, out_features=1280, bias=False\n                  (lora_layer): LoRALinearLayer(\n                    (down): Linear(in_features=1280, out_features=64, bias=False)\n                    (up): Linear(in_features=64, out_features=1280, bias=False)\n                  )\n                )\n                (to_v): LoRACompatibleLinear(\n                  in_features=1280, out_features=1280, bias=False\n                  (lora_layer): LoRALinearLayer(\n                    (down): Linear(in_features=1280, out_features=64, bias=False)\n                    (up): Linear(in_features=64, out_features=1280, bias=False)\n                  )\n                )\n                (to_out): ModuleList(\n                  (0): LoRACompatibleLinear(\n                    in_features=1280, out_features=1280, bias=True\n                    (lora_layer): LoRALinearLayer(\n                      (down): Linear(in_features=1280, out_features=64, bias=False)\n                      (up): Linear(in_features=64, out_features=1280, bias=False)\n                    )\n                  )\n                  (1): Dropout(p=0.0, inplace=False)\n                )\n              )\n              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n              (attn2): Attention(\n                (to_q): LoRACompatibleLinear(\n                  in_features=1280, out_features=1280, bias=False\n                  (lora_layer): LoRALinearLayer(\n                    (down): Linear(in_features=1280, out_features=64, bias=False)\n                    (up): Linear(in_features=64, out_features=1280, bias=False)\n                  )\n                )\n                (to_k): LoRACompatibleLinear(\n                  in_features=2048, out_features=1280, bias=False\n                  (lora_layer): LoRALinearLayer(\n                    (down): Linear(in_features=2048, out_features=64, bias=False)\n                    (up): Linear(in_features=64, out_features=1280, bias=False)\n                  )\n                )\n                (to_v): LoRACompatibleLinear(\n                  in_features=2048, out_features=1280, bias=False\n                  (lora_layer): LoRALinearLayer(\n                    (down): Linear(in_features=2048, out_features=64, bias=False)\n                    (up): Linear(in_features=64, out_features=1280, bias=False)\n                  )\n                )\n                (to_out): ModuleList(\n                  (0): LoRACompatibleLinear(\n                    in_features=1280, out_features=1280, bias=True\n                    (lora_layer): LoRALinearLayer(\n                      (down): Linear(in_features=1280, out_features=64, bias=False)\n                      (up): Linear(in_features=64, out_features=1280, bias=False)\n                    )\n                  )\n                  (1): Dropout(p=0.0, inplace=False)\n                )\n              )\n              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n              (ff): FeedForward(\n                (net): ModuleList(\n                  (0): GEGLU(\n                    (proj): LoRACompatibleLinear(in_features=1280, out_features=10240, bias=True)\n                  )\n                  (1): Dropout(p=0.0, inplace=False)\n                  (2): LoRACompatibleLinear(in_features=5120, out_features=1280, bias=True)\n                )\n              )\n            )\n          )\n          (proj_out): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n        )\n      )\n      (resnets): ModuleList(\n        (0-1): 2 x ResnetBlock2D(\n          (norm1): GroupNorm(32, 2560, eps=1e-05, affine=True)\n          (conv1): LoRACompatibleConv(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n          (conv_shortcut): LoRACompatibleConv(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (2): ResnetBlock2D(\n          (norm1): GroupNorm(32, 1920, eps=1e-05, affine=True)\n          (conv1): LoRACompatibleConv(1920, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n          (conv_shortcut): LoRACompatibleConv(1920, 1280, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (upsamplers): ModuleList(\n        (0): Upsample2D(\n          (conv): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n    )\n    (1): CrossAttnUpBlock2D(\n      (attentions): ModuleList(\n        (0-2): 3 x Transformer2DModel(\n          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n          (proj_in): LoRACompatibleLinear(in_features=640, out_features=640, bias=True)\n          (transformer_blocks): ModuleList(\n            (0-1): 2 x BasicTransformerBlock(\n              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n              (attn1): Attention(\n                (to_q): LoRACompatibleLinear(\n                  in_features=640, out_features=640, bias=False\n                  (lora_layer): LoRALinearLayer(\n                    (down): Linear(in_features=640, out_features=64, bias=False)\n                    (up): Linear(in_features=64, out_features=640, bias=False)\n                  )\n                )\n                (to_k): LoRACompatibleLinear(\n                  in_features=640, out_features=640, bias=False\n                  (lora_layer): LoRALinearLayer(\n                    (down): Linear(in_features=640, out_features=64, bias=False)\n                    (up): Linear(in_features=64, out_features=640, bias=False)\n                  )\n                )\n                (to_v): LoRACompatibleLinear(\n                  in_features=640, out_features=640, bias=False\n                  (lora_layer): LoRALinearLayer(\n                    (down): Linear(in_features=640, out_features=64, bias=False)\n                    (up): Linear(in_features=64, out_features=640, bias=False)\n                  )\n                )\n                (to_out): ModuleList(\n                  (0): LoRACompatibleLinear(\n                    in_features=640, out_features=640, bias=True\n                    (lora_layer): LoRALinearLayer(\n                      (down): Linear(in_features=640, out_features=64, bias=False)\n                      (up): Linear(in_features=64, out_features=640, bias=False)\n                    )\n                  )\n                  (1): Dropout(p=0.0, inplace=False)\n                )\n              )\n              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n              (attn2): Attention(\n                (to_q): LoRACompatibleLinear(\n                  in_features=640, out_features=640, bias=False\n                  (lora_layer): LoRALinearLayer(\n                    (down): Linear(in_features=640, out_features=64, bias=False)\n                    (up): Linear(in_features=64, out_features=640, bias=False)\n                  )\n                )\n                (to_k): LoRACompatibleLinear(\n                  in_features=2048, out_features=640, bias=False\n                  (lora_layer): LoRALinearLayer(\n                    (down): Linear(in_features=2048, out_features=64, bias=False)\n                    (up): Linear(in_features=64, out_features=640, bias=False)\n                  )\n                )\n                (to_v): LoRACompatibleLinear(\n                  in_features=2048, out_features=640, bias=False\n                  (lora_layer): LoRALinearLayer(\n                    (down): Linear(in_features=2048, out_features=64, bias=False)\n                    (up): Linear(in_features=64, out_features=640, bias=False)\n                  )\n                )\n                (to_out): ModuleList(\n                  (0): LoRACompatibleLinear(\n                    in_features=640, out_features=640, bias=True\n                    (lora_layer): LoRALinearLayer(\n                      (down): Linear(in_features=640, out_features=64, bias=False)\n                      (up): Linear(in_features=64, out_features=640, bias=False)\n                    )\n                  )\n                  (1): Dropout(p=0.0, inplace=False)\n                )\n              )\n              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n              (ff): FeedForward(\n                (net): ModuleList(\n                  (0): GEGLU(\n                    (proj): LoRACompatibleLinear(in_features=640, out_features=5120, bias=True)\n                  )\n                  (1): Dropout(p=0.0, inplace=False)\n                  (2): LoRACompatibleLinear(in_features=2560, out_features=640, bias=True)\n                )\n              )\n            )\n          )\n          (proj_out): LoRACompatibleLinear(in_features=640, out_features=640, bias=True)\n        )\n      )\n      (resnets): ModuleList(\n        (0): ResnetBlock2D(\n          (norm1): GroupNorm(32, 1920, eps=1e-05, affine=True)\n          (conv1): LoRACompatibleConv(1920, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=640, bias=True)\n          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n          (conv_shortcut): LoRACompatibleConv(1920, 640, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (1): ResnetBlock2D(\n          (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n          (conv1): LoRACompatibleConv(1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=640, bias=True)\n          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n          (conv_shortcut): LoRACompatibleConv(1280, 640, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (2): ResnetBlock2D(\n          (norm1): GroupNorm(32, 960, eps=1e-05, affine=True)\n          (conv1): LoRACompatibleConv(960, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=640, bias=True)\n          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n          (conv_shortcut): LoRACompatibleConv(960, 640, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (upsamplers): ModuleList(\n        (0): Upsample2D(\n          (conv): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n    )\n    (2): UpBlock2D(\n      (resnets): ModuleList(\n        (0): ResnetBlock2D(\n          (norm1): GroupNorm(32, 960, eps=1e-05, affine=True)\n          (conv1): LoRACompatibleConv(960, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=320, bias=True)\n          (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): LoRACompatibleConv(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n          (conv_shortcut): LoRACompatibleConv(960, 320, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (1-2): 2 x ResnetBlock2D(\n          (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)\n          (conv1): LoRACompatibleConv(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=320, bias=True)\n          (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): LoRACompatibleConv(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n          (conv_shortcut): LoRACompatibleConv(640, 320, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n    )\n  )\n  (mid_block): UNetMidBlock2DCrossAttn(\n    (attentions): ModuleList(\n      (0): Transformer2DModel(\n        (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n        (proj_in): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n        (transformer_blocks): ModuleList(\n          (0-9): 10 x BasicTransformerBlock(\n            (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n            (attn1): Attention(\n              (to_q): LoRACompatibleLinear(\n                in_features=1280, out_features=1280, bias=False\n                (lora_layer): LoRALinearLayer(\n                  (down): Linear(in_features=1280, out_features=64, bias=False)\n                  (up): Linear(in_features=64, out_features=1280, bias=False)\n                )\n              )\n              (to_k): LoRACompatibleLinear(\n                in_features=1280, out_features=1280, bias=False\n                (lora_layer): LoRALinearLayer(\n                  (down): Linear(in_features=1280, out_features=64, bias=False)\n                  (up): Linear(in_features=64, out_features=1280, bias=False)\n                )\n              )\n              (to_v): LoRACompatibleLinear(\n                in_features=1280, out_features=1280, bias=False\n                (lora_layer): LoRALinearLayer(\n                  (down): Linear(in_features=1280, out_features=64, bias=False)\n                  (up): Linear(in_features=64, out_features=1280, bias=False)\n                )\n              )\n              (to_out): ModuleList(\n                (0): LoRACompatibleLinear(\n                  in_features=1280, out_features=1280, bias=True\n                  (lora_layer): LoRALinearLayer(\n                    (down): Linear(in_features=1280, out_features=64, bias=False)\n                    (up): Linear(in_features=64, out_features=1280, bias=False)\n                  )\n                )\n                (1): Dropout(p=0.0, inplace=False)\n              )\n            )\n            (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n            (attn2): Attention(\n              (to_q): LoRACompatibleLinear(\n                in_features=1280, out_features=1280, bias=False\n                (lora_layer): LoRALinearLayer(\n                  (down): Linear(in_features=1280, out_features=64, bias=False)\n                  (up): Linear(in_features=64, out_features=1280, bias=False)\n                )\n              )\n              (to_k): LoRACompatibleLinear(\n                in_features=2048, out_features=1280, bias=False\n                (lora_layer): LoRALinearLayer(\n                  (down): Linear(in_features=2048, out_features=64, bias=False)\n                  (up): Linear(in_features=64, out_features=1280, bias=False)\n                )\n              )\n              (to_v): LoRACompatibleLinear(\n                in_features=2048, out_features=1280, bias=False\n                (lora_layer): LoRALinearLayer(\n                  (down): Linear(in_features=2048, out_features=64, bias=False)\n                  (up): Linear(in_features=64, out_features=1280, bias=False)\n                )\n              )\n              (to_out): ModuleList(\n                (0): LoRACompatibleLinear(\n                  in_features=1280, out_features=1280, bias=True\n                  (lora_layer): LoRALinearLayer(\n                    (down): Linear(in_features=1280, out_features=64, bias=False)\n                    (up): Linear(in_features=64, out_features=1280, bias=False)\n                  )\n                )\n                (1): Dropout(p=0.0, inplace=False)\n              )\n            )\n            (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n            (ff): FeedForward(\n              (net): ModuleList(\n                (0): GEGLU(\n                  (proj): LoRACompatibleLinear(in_features=1280, out_features=10240, bias=True)\n                )\n                (1): Dropout(p=0.0, inplace=False)\n                (2): LoRACompatibleLinear(in_features=5120, out_features=1280, bias=True)\n              )\n            )\n          )\n        )\n        (proj_out): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n      )\n    )\n    (resnets): ModuleList(\n      (0-1): 2 x ResnetBlock2D(\n        (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n        (conv1): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n        (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n        (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (nonlinearity): SiLU()\n      )\n    )\n  )\n  (conv_norm_out): GroupNorm(32, 320, eps=1e-05, affine=True)\n  (conv_act): SiLU()\n  (conv_out): Conv2d(320, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n)"},"metadata":{}}]},{"cell_type":"code","source":"list(lora_sd.items())[0][0]\n\nlook_up_list = ['.'+str(i) for i in range(10)]\n\n# base_params['unet']['up_blocks_0']['attentions_2']['transformer_blocks_8']['attn2']['to_k']\n# unet.unet.down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_k\n\ndef target_layer_from_sd_name(k):\n    lora_split_layer = k.split(\".lora.\")[0][5:]\n    for i in range(10):lora_split_layer = lora_split_layer.replace(f\".{i}\", f\"_{i}\")\n    layers = lora_split_layer.split('.')\n    []\n    target_layer = ''\n    for layer in layers:\n        target_layer += f\"['{layer}']\"\n    \n    return target_layer\n\n\ntarget_layer_from_sd_name(list(lora_sd.items())[0][0])\n# param_count = 0\n\n# def target_layer_from_sd_name(k):\n#     # They use slightly different naming schemes for attn processors vs the rest\n#     if '.processor.to_' in k:\n#         target_layer = k.split(\"processor.to_\")[0] + k.split(\".processor.\")[1].split(\"_lora\")[0]\n#         target_layer = target_layer.replace(\"to_out\", \"to_out[0]\")\n#     else:\n#         target_layer = k.split(\".lora.\")[0]\n#     # Replace '.1.' with '[1]' and so on:\n#     for i in range(10):target_layer = target_layer.replace(f\".{i}\", f\"[{i}]\")\n#     # Return (skipping the first 'unet.' in this case):\n#     return target_layer[5:]\n\n# for k, v in lora_sd.items():\n#     target_layer = target_layer_from_sd_name(k)\n#     aa, bb = eval(f'pipeline.{target_layer}').weight.data.shape\n#     param_count += aa+bb","metadata":{"execution":{"iopub.status.busy":"2023-11-28T11:11:32.282441Z","iopub.execute_input":"2023-11-28T11:11:32.283511Z","iopub.status.idle":"2023-11-28T11:11:32.294852Z","shell.execute_reply.started":"2023-11-28T11:11:32.283468Z","shell.execute_reply":"2023-11-28T11:11:32.293815Z"},"trusted":true},"execution_count":68,"outputs":[{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"\"['unet']['down_blocks_1']['attentions_0']['transformer_blocks_0']['attn1']['to_k']\""},"metadata":{}}]},{"cell_type":"code","source":"['unet']['up_blocks_0']['attentions_2']['transformer_blocks_8']['attn2']['to_k']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(int(list(lora_sd.items())[0][0].split(\".lora.\")[0].split('.')[4])) == int","metadata":{"execution":{"iopub.status.busy":"2023-11-28T10:56:04.658192Z","iopub.execute_input":"2023-11-28T10:56:04.659243Z","iopub.status.idle":"2023-11-28T10:56:04.715438Z","shell.execute_reply.started":"2023-11-28T10:56:04.659192Z","shell.execute_reply":"2023-11-28T10:56:04.713999Z"},"trusted":true},"execution_count":58,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1 \u001b[96mtype\u001b[0m(\u001b[96mint\u001b[0m(\u001b[96mlist\u001b[0m(lora_sd.items())[\u001b[94m0\u001b[0m][\u001b[94m0\u001b[0m].split(\u001b[33m\"\u001b[0m\u001b[33m.lora.\u001b[0m\u001b[33m\"\u001b[0m)[\u001b[94m0\u001b[0m].split(\u001b[33m'\u001b[0m\u001b[33m.\u001b[0m\u001b[33m'\u001b[0m)[\u001b[94m4\u001b[0m])) == \u001b[96mint\u001b[0m               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n\u001b[1;91mValueError: \u001b[0minvalid literal for \u001b[1;35mint\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m with base \u001b[1;36m10\u001b[0m: \u001b[32m'attentions'\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1 <span style=\"color: #00ffff; text-decoration-color: #00ffff\">type</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">int</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">list</span>(lora_sd.items())[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>][<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>].split(<span style=\"color: #808000; text-decoration-color: #808000\">\".lora.\"</span>)[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>].split(<span style=\"color: #808000; text-decoration-color: #808000\">'.'</span>)[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">4</span>])) == <span style=\"color: #00ffff; text-decoration-color: #00ffff\">int</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ValueError: </span>invalid literal for <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">int</span><span style=\"font-weight: bold\">()</span> with base <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'attentions'</span>\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-11-28T11:03:50.654551Z","iopub.execute_input":"2023-11-28T11:03:50.655467Z","iopub.status.idle":"2023-11-28T11:03:50.662162Z","shell.execute_reply.started":"2023-11-28T11:03:50.655426Z","shell.execute_reply":"2023-11-28T11:03:50.661182Z"},"trusted":true},"execution_count":67,"outputs":[{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"['.0', '.1', '.2', '.3', '.4', '.5', '.6', '.7', '.8', '.9']"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}